{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tours through the Book\n",
    "\n",
    "This book is _massive_.  With more than 20,000 lines of code and 150,000 words of text, a printed version would cover more than 1,200 pages of text.  Obviously, we do not assume that everybody wants to read everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "While the chapters of this book can be read one after the other, there are many possible paths through the book.  In this graph, an arrow $A \\rightarrow B$ means that chapter $A$ is a prerequisite for chapter $B$.  You can pick arbitrary paths in this graph to get to the topics that interest you most:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T13:44:47.366767Z",
     "iopub.status.busy": "2022-11-29T13:44:47.366365Z",
     "iopub.status.idle": "2022-11-29T13:44:47.409498Z",
     "shell.execute_reply": "2022-11-29T13:44:47.409759Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# ignore\n",
    "from bookutils import rich_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T13:44:47.412107Z",
     "iopub.status.busy": "2022-11-29T13:44:47.411742Z",
     "iopub.status.idle": "2022-11-29T13:44:47.441329Z",
     "shell.execute_reply": "2022-11-29T13:44:47.441527Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1325pt\" height=\"577pt\" viewBox=\"0.00 0.00 1324.95 577.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 573)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-573 1320.95,-573 1320.95,4 -4,4\"/>\n",
       "<!-- Fuzzer -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Fuzzer</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"Fuzzer.ipynb\" xlink:title=\"Fuzzing: Breaking Things with Random Inputs (Fuzzer)\n",
       "\n",
       "In this chapter, we'll start with one of the simplest test generation techniques.  The key idea of random text generation, also known as fuzzing, is to feed a string of random characters into a program in the hope to uncover failures.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"900.95,-495 763.95,-495 763.95,-442 906.95,-442 906.95,-489 900.95,-495\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"900.95,-495 900.95,-489 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"906.95,-489 900.95,-489 \"/>\n",
       "<text text-anchor=\"middle\" x=\"835.45\" y=\"-479.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Fuzzing: Breaking</text>\n",
       "<text text-anchor=\"middle\" x=\"835.45\" y=\"-464.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Things</text>\n",
       "<text text-anchor=\"middle\" x=\"835.45\" y=\"-449.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">with Random Inputs</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Coverage -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Coverage</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"Coverage.ipynb\" xlink:title=\"Code Coverage (Coverage)\n",
       "\n",
       "In the previous chapter, we introduced basic fuzzing – that is, generating random inputs to test programs.  How do we measure the effectiveness of these tests?  One way would be to check the number (and seriousness) of bugs found; but if bugs are scarce, we need a proxy for the likelihood of a test to uncover a bug.  In this chapter, we introduce the concept of code coverage, measuring which parts of a program are actually executed during a test run.  Measuring such coverage is also crucial for test generators that attempt to cover as much code as possible.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"504.95,-331 403.95,-331 403.95,-295 510.95,-295 510.95,-325 504.95,-331\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"504.95,-331 504.95,-325 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"510.95,-325 504.95,-325 \"/>\n",
       "<text text-anchor=\"middle\" x=\"457.45\" y=\"-309.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Code Coverage</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Fuzzer&#45;&gt;Coverage -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Fuzzer-&gt;Coverage</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M763.84,-453.72C718.01,-443.57 657.9,-427.74 607.45,-406 563.91,-387.24 518.04,-357.42 488.66,-336.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"490.65,-333.96 480.46,-331.03 486.6,-339.67 490.65,-333.96\"/>\n",
       "</g>\n",
       "<!-- SearchBasedFuzzer -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>SearchBasedFuzzer</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"SearchBasedFuzzer.ipynb\" xlink:title=\"Search-Based Fuzzing (SearchBasedFuzzer)\n",
       "\n",
       "Sometimes we are not only interested in fuzzing as many as possible diverse program inputs, but in deriving specific test inputs that achieve some objective, such as reaching specific statements in a program. When we have an idea of what we are looking for, then we can search for it. Search algorithms are at the core of computer science, but applying classic search algorithms like breadth or depth first search to search for tests is unrealistic, because these algorithms potentially require us to look at all possible inputs. However, domain-knowledge can be used to overcome this problem. For example, if we can estimate which of several program inputs is closer to the one we are looking for, then this information can guide us to reach the target quicker – this information is known as a heuristic. The way heuristics are applied systematically is captured in meta-heuristic search algorithms. The &quot;meta&quot; denotes that these algorithms are generic and can be instantiated differently to different problems. Meta-heuristics often take inspiration from processes observed in nature. For example, there are algorithms mimicking evolutionary processes, swarm intelligence, or chemical reactions. In general they are much more efficient than exhaustive search approaches such that they can be applied to vast search spaces – search spaces as vast as the domain of program inputs are no problem for them.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"762.45,-405 616.45,-405 616.45,-369 768.45,-369 768.45,-399 762.45,-405\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"762.45,-405 762.45,-399 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"768.45,-399 762.45,-399 \"/>\n",
       "<text text-anchor=\"middle\" x=\"692.45\" y=\"-383.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Search-Based Fuzzing</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Fuzzer&#45;&gt;SearchBasedFuzzer -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Fuzzer-&gt;SearchBasedFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M789.42,-441.91C770.92,-431.63 749.81,-419.89 732.02,-410\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"733.49,-406.81 723.05,-405.01 730.09,-412.93 733.49,-406.81\"/>\n",
       "</g>\n",
       "<!-- Grammars -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Grammars</title>\n",
       "<g id=\"a_node4\"><a xlink:href=\"Grammars.ipynb\" xlink:title=\"Fuzzing with Grammars (Grammars)\n",
       "\n",
       "In the chapter on &quot;Mutation-Based Fuzzing&quot;, we have seen how to use extra hints – such as sample input files – to speed up test generation.  In this chapter, we take this idea one step further, by providing a specification of the legal inputs to a program.  Specifying inputs via a grammar allows for very systematic and efficient test generation, in particular for complex input formats.  Grammars also serve as the base for configuration fuzzing, API fuzzing, GUI fuzzing, and many more.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"877.95,-406 786.95,-406 786.95,-368 883.95,-368 883.95,-400 877.95,-406\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"877.95,-406 877.95,-400 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"883.95,-400 877.95,-400 \"/>\n",
       "<text text-anchor=\"middle\" x=\"835.45\" y=\"-390.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Fuzzing with</text>\n",
       "<text text-anchor=\"middle\" x=\"835.45\" y=\"-375.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Grammars</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Fuzzer&#45;&gt;Grammars -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Fuzzer-&gt;Grammars</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M835.45,-441.91C835.45,-433.74 835.45,-424.65 835.45,-416.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"838.95,-416.24 835.45,-406.24 831.95,-416.24 838.95,-416.24\"/>\n",
       "</g>\n",
       "<!-- SymbolicFuzzer -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>SymbolicFuzzer</title>\n",
       "<g id=\"a_node5\"><a xlink:href=\"SymbolicFuzzer.ipynb\" xlink:title=\"Symbolic Fuzzing (SymbolicFuzzer)\n",
       "\n",
       "One of the problems with traditional methods of fuzzing is that they fail to exercise all the possible behaviors that a system can have, especially when the input space is large. Quite often the execution of a specific branch of execution may happen only with very specific inputs, which could represent an extremely small fraction of the input space. The traditional fuzzing methods relies on chance to produce inputs they need. However, relying on randomness to generate values that we want is a bad idea when the space to be explored is huge. For example, a function that accepts a string, even if one only considers the first $10$ characters, already has $2^{80}$ possible inputs. If one is looking for a specific string, random generation of values will take a few thousand years even in one of the super computers.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"1020.95,-405 901.95,-405 901.95,-369 1026.95,-369 1026.95,-399 1020.95,-405\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1020.95,-405 1020.95,-399 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1026.95,-399 1020.95,-399 \"/>\n",
       "<text text-anchor=\"middle\" x=\"964.45\" y=\"-383.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Symbolic Fuzzing</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Fuzzer&#45;&gt;SymbolicFuzzer -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Fuzzer-&gt;SymbolicFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M876.98,-441.91C893.51,-431.72 912.35,-420.11 928.31,-410.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"930.17,-413.24 936.84,-405.01 926.49,-407.28 930.17,-413.24\"/>\n",
       "</g>\n",
       "<!-- FuzzingInTheLarge -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>FuzzingInTheLarge</title>\n",
       "<g id=\"a_node6\"><a xlink:href=\"FuzzingInTheLarge.ipynb\" xlink:title=\"Fuzzing in the Large (FuzzingInTheLarge)\n",
       "\n",
       "In the past chapters, we have always looked at fuzzing taking place on one machine for a few seconds only.  In the real world, however, fuzzers are run on dozens or even thousands of machines; for hours, days and weeks; for one program or dozens of programs.  In such contexts, one needs an infrastructure to collect failure data from the individual fuzzer runs, and to aggregate such data in a central repository.  In this chapter, we will examine such an infrastructure, the FuzzManager framework from Mozilla.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"1179.45,-405 1045.45,-405 1045.45,-369 1185.45,-369 1185.45,-399 1179.45,-405\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1179.45,-405 1179.45,-399 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1185.45,-399 1179.45,-399 \"/>\n",
       "<text text-anchor=\"middle\" x=\"1115.45\" y=\"-383.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Fuzzing in the Large</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Fuzzer&#45;&gt;FuzzingInTheLarge -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>Fuzzer-&gt;FuzzingInTheLarge</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M907.19,-447.13C949.74,-435.05 1003.41,-419.81 1045.61,-407.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1046.59,-411.19 1055.25,-405.09 1044.68,-404.46 1046.59,-411.19\"/>\n",
       "</g>\n",
       "<!-- MutationFuzzer -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>MutationFuzzer</title>\n",
       "<g id=\"a_node8\"><a xlink:href=\"MutationFuzzer.ipynb\" xlink:title=\"Mutation-Based Fuzzing (MutationFuzzer)\n",
       "\n",
       "Most randomly generated inputs are syntactically invalid and thus are quickly rejected by the processing program.  To exercise functionality beyond input processing, we must increase chances to obtain valid inputs.  One such way is so-called mutational fuzzing – that is, introducing small changes to existing inputs that may still keep the input valid, yet exercise new behavior.  We show how to create such mutations, and how to guide them towards yet uncovered code, applying central concepts from the popular AFL fuzzer.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"587.45,-258 475.45,-258 475.45,-220 593.45,-220 593.45,-252 587.45,-258\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"587.45,-258 587.45,-252 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"593.45,-252 587.45,-252 \"/>\n",
       "<text text-anchor=\"middle\" x=\"534.45\" y=\"-242.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Mutation-Based</text>\n",
       "<text text-anchor=\"middle\" x=\"534.45\" y=\"-227.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Fuzzing</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Coverage&#45;&gt;MutationFuzzer -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>Coverage-&gt;MutationFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M475.7,-294.94C485.22,-286.04 497.05,-274.98 507.59,-265.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"510.07,-267.59 514.99,-258.2 505.29,-262.47 510.07,-267.59\"/>\n",
       "</g>\n",
       "<!-- MutationAnalysis -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>MutationAnalysis</title>\n",
       "<g id=\"a_node9\"><a xlink:href=\"MutationAnalysis.ipynb\" xlink:title=\"Mutation Analysis (MutationAnalysis)\n",
       "\n",
       "In the chapter on coverage, we showed how one can identify which parts of the program are executed by a program, and hence get a sense of the effectiveness of a set of test cases in covering the program structure.  However, coverage alone may not be the best measure for the effectiveness of a test, as one can have great coverage without ever checking a result for correctness.  In this chapter, we introduce another means for assessing the effectiveness of a test suite: After injecting mutations – artificial faults – into the code, we check whether a test suite can detect these artificial faults.  The idea is that if it fails to detect such mutations, it will also miss real bugs.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"141.45,-257 17.45,-257 17.45,-221 147.45,-221 147.45,-251 141.45,-257\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"141.45,-257 141.45,-251 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"147.45,-251 141.45,-251 \"/>\n",
       "<text text-anchor=\"middle\" x=\"82.45\" y=\"-235.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Mutation Analysis</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Coverage&#45;&gt;MutationAnalysis -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>Coverage-&gt;MutationAnalysis</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M403.7,-303.38C345.46,-293.8 249.59,-277.38 157.79,-258.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"158.28,-254.75 147.77,-256.12 156.84,-261.6 158.28,-254.75\"/>\n",
       "</g>\n",
       "<!-- GrammarCoverageFuzzer -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>GrammarCoverageFuzzer</title>\n",
       "<g id=\"a_node10\"><a xlink:href=\"GrammarCoverageFuzzer.ipynb\" xlink:title=\"Grammar Coverage (GrammarCoverageFuzzer)\n",
       "\n",
       "Producing inputs from grammars gives all possible expansions of a rule the same likelihood.  For producing a comprehensive test suite, however, it makes more sense to maximize variety – for instance, by not repeating the same expansions over and over again.  In this chapter, we explore how to systematically cover elements of a grammar such that we maximize variety and do not miss out individual elements.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"941.45,-257 811.45,-257 811.45,-221 947.45,-221 947.45,-251 941.45,-257\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"941.45,-257 941.45,-251 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"947.45,-251 941.45,-251 \"/>\n",
       "<text text-anchor=\"middle\" x=\"879.45\" y=\"-235.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Grammar Coverage</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Coverage&#45;&gt;GrammarCoverageFuzzer -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>Coverage-&gt;GrammarCoverageFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M511.15,-304.86C577.13,-295.8 692.69,-279.03 800.96,-258.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"801.92,-261.6 811.07,-256.26 800.59,-254.73 801.92,-261.6\"/>\n",
       "</g>\n",
       "<!-- ProbabilisticGrammarFuzzer -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>ProbabilisticGrammarFuzzer</title>\n",
       "<g id=\"a_node11\"><a xlink:href=\"ProbabilisticGrammarFuzzer.ipynb\" xlink:title=\"Probabilistic Grammar Fuzzing (ProbabilisticGrammarFuzzer)\n",
       "\n",
       "Let us give grammars even more power by assigning probabilities to individual expansions.  This allows us to control how many of each element should be produced, and thus allows us to target our generated tests towards specific functionality.  We also show how to learn such probabilities from given sample inputs, and specifically direct our tests towards input features that are uncommon in these samples.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"486.95,-184 365.95,-184 365.95,-146 492.95,-146 492.95,-178 486.95,-184\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"486.95,-184 486.95,-178 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"492.95,-178 486.95,-178 \"/>\n",
       "<text text-anchor=\"middle\" x=\"429.45\" y=\"-168.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Probabilistic</text>\n",
       "<text text-anchor=\"middle\" x=\"429.45\" y=\"-153.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Grammar Fuzzing</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Coverage&#45;&gt;ProbabilisticGrammarFuzzer -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>Coverage-&gt;ProbabilisticGrammarFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M403.58,-309.46C290.02,-303.56 34.3,-287.15 8.45,-258 -2.76,-245.36 -2.86,-232.54 8.45,-220 58.59,-164.41 263.81,-194.86 355.75,-183.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"356.47,-187.14 365.86,-182.23 355.46,-180.22 356.47,-187.14\"/>\n",
       "</g>\n",
       "<!-- ConcolicFuzzer -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>ConcolicFuzzer</title>\n",
       "<g id=\"a_node12\"><a xlink:href=\"ConcolicFuzzer.ipynb\" xlink:title=\"Concolic Fuzzing (ConcolicFuzzer)\n",
       "\n",
       "In the chapter on information flow, we have seen how one can use dynamic taints to produce more intelligent test cases than simply looking for program crashes. We have also seen how one can use the taints to update the grammar, and hence focus more on the dangerous methods.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"816.95,-109 703.95,-109 703.95,-73 822.95,-73 822.95,-103 816.95,-109\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"816.95,-109 816.95,-103 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"822.95,-103 816.95,-103 \"/>\n",
       "<text text-anchor=\"middle\" x=\"763.45\" y=\"-87.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Concolic Fuzzing</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Coverage&#45;&gt;ConcolicFuzzer -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>Coverage-&gt;ConcolicFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M511.1,-298.26C539.67,-289.45 574.56,-276.22 602.45,-258 633.96,-237.42 705.68,-157.94 741.81,-116.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"744.57,-119.03 748.53,-109.2 739.31,-114.41 744.57,-119.03\"/>\n",
       "</g>\n",
       "<!-- DynamicInvariants -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>DynamicInvariants</title>\n",
       "<g id=\"a_node13\"><a xlink:href=\"DynamicInvariants.ipynb\" xlink:title=\"Mining Function Specifications (DynamicInvariants)\n",
       "\n",
       "When testing a program, one not only needs to cover its several behaviors; one also needs to check whether the result is as expected.  In this chapter, we introduce a technique that allows us to mine function specifications from a set of given executions, resulting in abstract and formal descriptions of what the function expects and what it delivers.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"278.95,-258 165.95,-258 165.95,-220 284.95,-220 284.95,-252 278.95,-258\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"278.95,-258 278.95,-252 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"284.95,-252 278.95,-252 \"/>\n",
       "<text text-anchor=\"middle\" x=\"225.45\" y=\"-242.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Mining Function</text>\n",
       "<text text-anchor=\"middle\" x=\"225.45\" y=\"-227.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Specifications</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Coverage&#45;&gt;DynamicInvariants -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>Coverage-&gt;DynamicInvariants</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M403.93,-295.39C371.03,-285.18 328.57,-272 293.31,-261.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"294.16,-257.66 283.57,-258.04 292.09,-264.35 294.16,-257.66\"/>\n",
       "</g>\n",
       "<!-- WhenToStopFuzzing -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>WhenToStopFuzzing</title>\n",
       "<g id=\"a_node14\"><a xlink:href=\"WhenToStopFuzzing.ipynb\" xlink:title=\"When To Stop Fuzzing (WhenToStopFuzzing)\n",
       "\n",
       "In the past chapters, we have discussed several fuzzing techniques.  Knowing what to do is important, but it is also important to know when to stop doing things.  In this chapter, we will learn when to stop fuzzing – and use a prominent example for this purpose: The Enigma machine that was used in the second world war by the navy of Nazi Germany to encrypt communications, and how Alan Turing and I.J. Good used fuzzing techniques to crack ciphers for the Naval Enigma machine.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"451.45,-257 303.45,-257 303.45,-221 457.45,-221 457.45,-251 451.45,-257\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"451.45,-257 451.45,-251 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"457.45,-251 451.45,-251 \"/>\n",
       "<text text-anchor=\"middle\" x=\"380.45\" y=\"-235.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">When To Stop Fuzzing</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Coverage&#45;&gt;WhenToStopFuzzing -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>Coverage-&gt;WhenToStopFuzzing</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M439.2,-294.94C429.4,-285.77 417.14,-274.31 406.36,-264.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"408.53,-261.46 398.83,-257.19 403.75,-266.58 408.53,-261.46\"/>\n",
       "</g>\n",
       "<!-- GrammarFuzzer -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>GrammarFuzzer</title>\n",
       "<g id=\"a_node17\"><a xlink:href=\"GrammarFuzzer.ipynb\" xlink:title=\"Efficient Grammar Fuzzing (GrammarFuzzer)\n",
       "\n",
       "In the chapter on grammars, we have seen how to use grammars for very effective and efficient testing.  In this chapter, we refine the previous string-based algorithm into a tree-based algorithm, which is much faster and allows for much more control over the production of fuzz inputs.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"938.45,-332 814.45,-332 814.45,-294 944.45,-294 944.45,-326 938.45,-332\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"938.45,-332 938.45,-326 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"944.45,-326 938.45,-326 \"/>\n",
       "<text text-anchor=\"middle\" x=\"879.45\" y=\"-316.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Efficient Grammar</text>\n",
       "<text text-anchor=\"middle\" x=\"879.45\" y=\"-301.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Fuzzing</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Grammars&#45;&gt;GrammarFuzzer -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>Grammars-&gt;GrammarFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M846.55,-367.83C851.52,-359.71 857.47,-349.96 862.94,-341.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"865.97,-342.77 868.2,-332.41 860,-339.12 865.97,-342.77\"/>\n",
       "</g>\n",
       "<!-- Intro_Testing -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>Intro_Testing</title>\n",
       "<g id=\"a_node7\"><a xlink:href=\"Intro_Testing.ipynb\" xlink:title=\"Introduction to Software Testing (Intro_Testing)\n",
       "\n",
       "Before we get to the central parts of the book, let us introduce essential concepts of software testing.  Why is it necessary to test software at all?  How does one test software?  How can one tell whether a test has been successful?  How does one know if one has tested enough?  In this chapter, let us recall the most important concepts, and at the same time get acquainted with Python and interactive notebooks.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"890.45,-569 774.45,-569 774.45,-531 896.45,-531 896.45,-563 890.45,-569\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"890.45,-569 890.45,-563 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"896.45,-563 890.45,-563 \"/>\n",
       "<text text-anchor=\"middle\" x=\"835.45\" y=\"-553.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Introduction to</text>\n",
       "<text text-anchor=\"middle\" x=\"835.45\" y=\"-538.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Software Testing</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Intro_Testing&#45;&gt;Fuzzer -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Intro_Testing-&gt;Fuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M835.45,-530.96C835.45,-523.32 835.45,-514.14 835.45,-505.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"838.95,-505 835.45,-495 831.95,-505 838.95,-505\"/>\n",
       "</g>\n",
       "<!-- GreyboxFuzzer -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>GreyboxFuzzer</title>\n",
       "<g id=\"a_node15\"><a xlink:href=\"GreyboxFuzzer.ipynb\" xlink:title=\"Greybox Fuzzing (GreyboxFuzzer)\n",
       "\n",
       "In the previous chapter, we have introduced mutation-based fuzzing, a technique that generates fuzz inputs by applying small mutations to given inputs. In this chapter, we show how to guide these mutations towards specific goals such as coverage. The algorithms in this chapter stem from the popular American Fuzzy Lop (AFL) fuzzer, in particular from its AFLFast and AFLGo flavors. We will explore the greybox fuzzing algorithm behind AFL and how we can exploit it to solve various problems for automated vulnerability detection.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"625.45,-183 511.45,-183 511.45,-147 631.45,-147 631.45,-177 625.45,-183\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"625.45,-183 625.45,-177 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"631.45,-177 625.45,-177 \"/>\n",
       "<text text-anchor=\"middle\" x=\"571.45\" y=\"-161.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Greybox Fuzzing</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- MutationFuzzer&#45;&gt;GreyboxFuzzer -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>MutationFuzzer-&gt;GreyboxFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M543.79,-219.83C548.05,-211.55 553.17,-201.57 557.85,-192.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"561.04,-193.91 562.5,-183.42 554.82,-190.71 561.04,-193.91\"/>\n",
       "</g>\n",
       "<!-- GrammarMiner -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>GrammarMiner</title>\n",
       "<g id=\"a_node23\"><a xlink:href=\"GrammarMiner.ipynb\" xlink:title=\"Mining Input Grammars (GrammarMiner)\n",
       "\n",
       "So far, the grammars we have seen have been mostly specified manually – that is, you (or the person knowing the input format) had to design and write a grammar in the first place.  While the grammars we have seen so far have been rather simple, creating a grammar for complex inputs can involve quite some effort.  In this chapter, we therefore introduce techniques that automatically mine grammars from programs – by executing the programs and observing how they process which parts of the input.  In conjunction with a grammar fuzzer, this allows us to \n",
       "1. take a program, \n",
       "2. extract its input grammar, and \n",
       "3. fuzz it with high efficiency and effectiveness, using the concepts in this book.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"984.45,-110 892.45,-110 892.45,-72 990.45,-72 990.45,-104 984.45,-110\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"984.45,-110 984.45,-104 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"990.45,-104 984.45,-104 \"/>\n",
       "<text text-anchor=\"middle\" x=\"941.45\" y=\"-94.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Mining Input</text>\n",
       "<text text-anchor=\"middle\" x=\"941.45\" y=\"-79.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Grammars</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- GrammarCoverageFuzzer&#45;&gt;GrammarMiner -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>GrammarCoverageFuzzer-&gt;GrammarMiner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M938.47,-220.99C969.36,-210.76 1002.58,-197.21 1011.45,-184 1020.86,-169.98 1018.9,-161.16 1011.45,-146 1005.63,-134.15 995.82,-124.17 985.35,-116.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"987.06,-113.06 976.89,-110.12 983.01,-118.76 987.06,-113.06\"/>\n",
       "</g>\n",
       "<!-- ConfigurationFuzzer -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>ConfigurationFuzzer</title>\n",
       "<g id=\"a_node24\"><a xlink:href=\"ConfigurationFuzzer.ipynb\" xlink:title=\"Testing Configurations (ConfigurationFuzzer)\n",
       "\n",
       "The behavior of a program is not only governed by its data.  The configuration of a program – that is, the settings that govern the execution of a program on its (regular) input data, as set by options or configuration files – just as well influences behavior, and thus can and should be tested.  In this chapter, we explore how to systematically test and cover software configurations.  By automatically inferring configuration options, we can apply these techniques out of the box, with no need for writing a grammar.  Finally, we show how to systematically cover combinations of configuration options, quickly detecting unwanted interferences.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"995.95,-184 892.95,-184 892.95,-146 1001.95,-146 1001.95,-178 995.95,-184\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"995.95,-184 995.95,-178 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1001.95,-178 995.95,-178 \"/>\n",
       "<text text-anchor=\"middle\" x=\"947.45\" y=\"-168.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Testing</text>\n",
       "<text text-anchor=\"middle\" x=\"947.45\" y=\"-153.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Configurations</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- GrammarCoverageFuzzer&#45;&gt;ConfigurationFuzzer -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>GrammarCoverageFuzzer-&gt;ConfigurationFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M895.57,-220.94C903.81,-212.21 914.01,-201.4 923.19,-191.69\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"925.94,-193.87 930.26,-184.2 920.85,-189.07 925.94,-193.87\"/>\n",
       "</g>\n",
       "<!-- Carver -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>Carver</title>\n",
       "<g id=\"a_node25\"><a xlink:href=\"Carver.ipynb\" xlink:title=\"Carving Unit Tests (Carver)\n",
       "\n",
       "So far, we have always generated system input, i.e. data that the program as a whole obtains via its input channels.  If we are interested in testing only a small set of functions, having to go through the system can be very inefficient.  This chapter introduces a technique known as carving, which, given a system test, automatically extracts a set of unit tests that replicate the calls seen during the system test.  The key idea is to record such calls such that we can replay them later – as a whole or selectively.  On top, we also explore how to synthesize API grammars from carved unit tests; this means that we can synthesize API tests without having to write a grammar at all.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"807.45,-36 683.45,-36 683.45,0 813.45,0 813.45,-30 807.45,-36\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"807.45,-36 807.45,-30 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"813.45,-30 807.45,-30 \"/>\n",
       "<text text-anchor=\"middle\" x=\"748.45\" y=\"-14.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Carving Unit Tests</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- GrammarCoverageFuzzer&#45;&gt;Carver -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>GrammarCoverageFuzzer-&gt;Carver</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M947.59,-221.46C981.96,-211.6 1018.46,-198.25 1028.45,-184 1050.21,-152.97 1000.13,-72.57 999.45,-72 973.28,-49.84 887.75,-35.16 823.76,-26.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"824.04,-23.49 813.69,-25.72 823.18,-30.43 824.04,-23.49\"/>\n",
       "</g>\n",
       "<!-- GUIFuzzer -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>GUIFuzzer</title>\n",
       "<g id=\"a_node26\"><a xlink:href=\"GUIFuzzer.ipynb\" xlink:title=\"Testing Graphical User Interfaces (GUIFuzzer)\n",
       "\n",
       "In this chapter, we explore how to generate tests for Graphical User Interfaces (GUIs), abstracting from our previous examples on Web testing.  Building on general means to extract user interface elements and activate them, our techniques generalize to arbitrary graphical user interfaces, from rich Web applications to mobile apps, and systematically explore user interfaces through forms and navigation elements.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"1270.45,-184 1152.45,-184 1152.45,-146 1276.45,-146 1276.45,-178 1270.45,-184\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1270.45,-184 1270.45,-178 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1276.45,-178 1270.45,-178 \"/>\n",
       "<text text-anchor=\"middle\" x=\"1214.45\" y=\"-168.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Testing Graphical</text>\n",
       "<text text-anchor=\"middle\" x=\"1214.45\" y=\"-153.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">User Interfaces</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- GrammarCoverageFuzzer&#45;&gt;GUIFuzzer -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>GrammarCoverageFuzzer-&gt;GUIFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M947.45,-222.01C950.49,-221.33 953.5,-220.65 956.45,-220 1019.07,-206.13 1090.46,-191.26 1142.24,-180.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1143.23,-184.01 1152.33,-178.58 1141.83,-177.16 1143.23,-184.01\"/>\n",
       "</g>\n",
       "<!-- APIFuzzer -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>APIFuzzer</title>\n",
       "<g id=\"a_node28\"><a xlink:href=\"APIFuzzer.ipynb\" xlink:title=\"Fuzzing APIs (APIFuzzer)\n",
       "\n",
       "So far, we have always generated system input, i.e. data that the program as a whole obtains via its input channels.  However, we can also generate inputs that go directly into individual functions, gaining flexibility and speed in the process.  In this chapter, we explore the use of grammars to synthesize code for function calls, which allows you to generate program code that very efficiently invokes functions directly.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"471.45,-109 381.45,-109 381.45,-73 477.45,-73 477.45,-103 471.45,-109\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"471.45,-109 471.45,-103 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"477.45,-103 471.45,-103 \"/>\n",
       "<text text-anchor=\"middle\" x=\"429.45\" y=\"-87.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Fuzzing APIs</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- ProbabilisticGrammarFuzzer&#45;&gt;APIFuzzer -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>ProbabilisticGrammarFuzzer-&gt;APIFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M429.45,-145.83C429.45,-137.89 429.45,-128.41 429.45,-119.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.95,-119.42 429.45,-109.42 425.95,-119.42 432.95,-119.42\"/>\n",
       "</g>\n",
       "<!-- GreyboxGrammarFuzzer -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>GreyboxGrammarFuzzer</title>\n",
       "<g id=\"a_node16\"><a xlink:href=\"GreyboxGrammarFuzzer.ipynb\" xlink:title=\"Greybox Fuzzing with Grammars (GreyboxGrammarFuzzer)\n",
       "\n",
       "In this chapter, we introduce important extensions to our syntactic fuzzing techniques, all leveraging syntactic parts of existing inputs.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"660.45,-110 514.45,-110 514.45,-72 666.45,-72 666.45,-104 660.45,-110\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"660.45,-110 660.45,-104 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"666.45,-104 660.45,-104 \"/>\n",
       "<text text-anchor=\"middle\" x=\"590.45\" y=\"-94.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Greybox Fuzzing with</text>\n",
       "<text text-anchor=\"middle\" x=\"590.45\" y=\"-79.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Grammars</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- GreyboxFuzzer&#45;&gt;GreyboxGrammarFuzzer -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>GreyboxFuzzer-&gt;GreyboxGrammarFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M575.95,-146.94C578.07,-138.9 580.66,-129.1 583.06,-120.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"586.48,-120.76 585.65,-110.2 579.71,-118.98 586.48,-120.76\"/>\n",
       "</g>\n",
       "<!-- GrammarFuzzer&#45;&gt;GrammarCoverageFuzzer -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>GrammarFuzzer-&gt;GrammarCoverageFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M879.45,-293.83C879.45,-285.89 879.45,-276.41 879.45,-267.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"882.95,-267.42 879.45,-257.42 875.95,-267.42 882.95,-267.42\"/>\n",
       "</g>\n",
       "<!-- Parser -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>Parser</title>\n",
       "<g id=\"a_node18\"><a xlink:href=\"Parser.ipynb\" xlink:title=\"Parsing Inputs (Parser)\n",
       "\n",
       "In the chapter on Grammars, we discussed how grammars can be\n",
       "used to represent various languages. We also saw how grammars can be used to\n",
       "generate strings of the corresponding language. Grammars can also perform the\n",
       "reverse. That is, given a string, one can decompose the string into its\n",
       "constituent parts that correspond to the parts of grammar used to generate it\n",
       "– the derivation tree of that string. These parts (and parts from other similar\n",
       "strings) can later be recombined using the same grammar to produce new strings.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"787.45,-257 687.45,-257 687.45,-221 793.45,-221 793.45,-251 787.45,-257\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"787.45,-257 787.45,-251 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"793.45,-251 787.45,-251 \"/>\n",
       "<text text-anchor=\"middle\" x=\"740.45\" y=\"-235.3\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Parsing Inputs</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- GrammarFuzzer&#45;&gt;Parser -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>GrammarFuzzer-&gt;Parser</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M844.38,-293.83C825.63,-284.12 802.41,-272.1 782.68,-261.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"784.09,-258.66 773.6,-257.17 780.87,-264.88 784.09,-258.66\"/>\n",
       "</g>\n",
       "<!-- GeneratorGrammarFuzzer -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>GeneratorGrammarFuzzer</title>\n",
       "<g id=\"a_node19\"><a xlink:href=\"GeneratorGrammarFuzzer.ipynb\" xlink:title=\"Fuzzing with Generators (GeneratorGrammarFuzzer)\n",
       "\n",
       "In this chapter, we show how to extend grammars with functions – pieces of code that get executed during grammar expansion, and that can generate, check, or change elements produced.  Adding functions to a grammar allows for very versatile test generation, bringing together the best of grammar generation and programming.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"341.95,-184 250.95,-184 250.95,-146 347.95,-146 347.95,-178 341.95,-184\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"341.95,-184 341.95,-178 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"347.95,-178 341.95,-178 \"/>\n",
       "<text text-anchor=\"middle\" x=\"299.45\" y=\"-168.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Fuzzing with</text>\n",
       "<text text-anchor=\"middle\" x=\"299.45\" y=\"-153.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Generators</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- GrammarFuzzer&#45;&gt;GeneratorGrammarFuzzer -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>GrammarFuzzer-&gt;GeneratorGrammarFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M814.13,-297.97C774.3,-288.56 722.7,-274.81 678.45,-258 643.15,-244.59 638.48,-231.32 602.45,-220 500.12,-187.84 466.14,-207.48 358.11,-184.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"358.65,-180.7 348.13,-181.94 357.12,-187.53 358.65,-180.7\"/>\n",
       "</g>\n",
       "<!-- Reducer -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>Reducer</title>\n",
       "<g id=\"a_node20\"><a xlink:href=\"Reducer.ipynb\" xlink:title=\"Reducing Failure-Inducing Inputs (Reducer)\n",
       "\n",
       "By construction, fuzzers create inputs that may be hard to read.  This causes issues during debugging, when a human has to analyze the exact cause of the failure.  In this chapter, we present techniques that automatically reduce and simplify failure-inducing inputs to a minimum in order to ease debugging.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"1084.95,-258 965.95,-258 965.95,-220 1090.95,-220 1090.95,-252 1084.95,-258\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1084.95,-258 1084.95,-252 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1090.95,-252 1084.95,-252 \"/>\n",
       "<text text-anchor=\"middle\" x=\"1028.45\" y=\"-242.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Reducing Failure-</text>\n",
       "<text text-anchor=\"middle\" x=\"1028.45\" y=\"-227.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Inducing Inputs</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- GrammarFuzzer&#45;&gt;Reducer -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>GrammarFuzzer-&gt;Reducer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M917.05,-293.83C936.8,-284.29 961.18,-272.51 982.09,-262.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"983.64,-265.54 991.12,-258.04 980.6,-259.24 983.64,-265.54\"/>\n",
       "</g>\n",
       "<!-- FuzzingWithConstraints -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>FuzzingWithConstraints</title>\n",
       "<g id=\"a_node21\"><a xlink:href=\"FuzzingWithConstraints.ipynb\" xlink:title=\"Fuzzing with Constraints (FuzzingWithConstraints)\n",
       "\n",
       "In previous chapters, we have seen how Grammar-Based Fuzzing allows us to efficiently generate myriads of syntactically valid inputs.\n",
       "However, there are semantic input features that cannot be expressed in a context-free grammar, such as\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"1199.95,-258 1108.95,-258 1108.95,-220 1205.95,-220 1205.95,-252 1199.95,-258\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1199.95,-258 1199.95,-252 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1205.95,-252 1199.95,-252 \"/>\n",
       "<text text-anchor=\"middle\" x=\"1157.45\" y=\"-242.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Fuzzing with</text>\n",
       "<text text-anchor=\"middle\" x=\"1157.45\" y=\"-227.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Constraints</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- GrammarFuzzer&#45;&gt;FuzzingWithConstraints -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>GrammarFuzzer-&gt;FuzzingWithConstraints</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M944.54,-297.29C986.3,-287.58 1041.86,-274.14 1098.8,-258.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1100,-261.69 1108.7,-255.63 1098.12,-254.94 1100,-261.69\"/>\n",
       "</g>\n",
       "<!-- WebFuzzer -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>WebFuzzer</title>\n",
       "<g id=\"a_node22\"><a xlink:href=\"WebFuzzer.ipynb\" xlink:title=\"Testing Web Applications (WebFuzzer)\n",
       "\n",
       "In this chapter, we explore how to generate tests for Graphical User Interfaces (GUIs), notably on Web interfaces.  We set up a (vulnerable) Web server and demonstrate how to systematically explore its behavior – first with hand-written grammars, then with grammars automatically inferred from the user interface.  We also show how to conduct systematic attacks on these servers, notably with code and SQL injection.\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"1310.95,-258 1223.95,-258 1223.95,-220 1316.95,-220 1316.95,-252 1310.95,-258\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1310.95,-258 1310.95,-252 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1316.95,-252 1310.95,-252 \"/>\n",
       "<text text-anchor=\"middle\" x=\"1270.45\" y=\"-242.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Testing Web</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.45\" y=\"-227.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Applications</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- GrammarFuzzer&#45;&gt;WebFuzzer -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>GrammarFuzzer-&gt;WebFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M944.46,-304.63C1010.39,-296.46 1115.4,-281.55 1213.96,-258.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1214.88,-261.56 1223.79,-255.82 1213.25,-254.76 1214.88,-261.56\"/>\n",
       "</g>\n",
       "<!-- Parser&#45;&gt;ProbabilisticGrammarFuzzer -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>Parser-&gt;ProbabilisticGrammarFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M687.45,-226.27C641.34,-216 572.47,-200.5 502.95,-184.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"503.67,-180.67 493.14,-181.78 502.06,-187.48 503.67,-180.67\"/>\n",
       "</g>\n",
       "<!-- Parser&#45;&gt;GreyboxGrammarFuzzer -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>Parser-&gt;GreyboxGrammarFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M722.95,-220.97C696.73,-195.45 647.09,-147.13 616.57,-117.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"618.86,-114.76 609.25,-110.3 613.97,-119.78 618.86,-114.76\"/>\n",
       "</g>\n",
       "<!-- InformationFlow -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>InformationFlow</title>\n",
       "<g id=\"a_node27\"><a xlink:href=\"InformationFlow.ipynb\" xlink:title=\"Tracking Information Flow (InformationFlow)\n",
       "\n",
       "We have explored how one could generate better inputs that can penetrate deeper into the program in question. While doing so, we have relied on program crashes to tell us that we have succeeded in finding problems in the program. However, that is rather simplistic. What if the behavior of the program is simply incorrect, but does not lead to a crash? Can one do better?\">\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"868.95,-184 725.95,-184 725.95,-146 874.95,-146 874.95,-178 868.95,-184\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"868.95,-184 868.95,-178 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"874.95,-178 868.95,-178 \"/>\n",
       "<text text-anchor=\"middle\" x=\"800.45\" y=\"-168.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Tracking Information</text>\n",
       "<text text-anchor=\"middle\" x=\"800.45\" y=\"-153.8\" font-family=\"Patua One, Helvetica, sans-serif\" font-size=\"14.00\" fill=\"#b03a2e\">Flow</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Parser&#45;&gt;InformationFlow -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>Parser-&gt;InformationFlow</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M754.67,-220.94C761.87,-212.3 770.77,-201.62 778.8,-191.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"781.57,-194.12 785.28,-184.2 776.19,-189.64 781.57,-194.12\"/>\n",
       "</g>\n",
       "<!-- GeneratorGrammarFuzzer&#45;&gt;APIFuzzer -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>GeneratorGrammarFuzzer-&gt;APIFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M332.26,-145.83C349.63,-136.21 371.11,-124.31 389.45,-114.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"391.39,-117.08 398.45,-109.17 388,-110.95 391.39,-117.08\"/>\n",
       "</g>\n",
       "<!-- WebFuzzer&#45;&gt;GUIFuzzer -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>WebFuzzer-&gt;GUIFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1256.32,-219.83C1249.87,-211.54 1242.11,-201.56 1235.03,-192.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1237.67,-190.16 1228.77,-184.41 1232.15,-194.46 1237.67,-190.16\"/>\n",
       "</g>\n",
       "<!-- InformationFlow&#45;&gt;ConcolicFuzzer -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>InformationFlow-&gt;ConcolicFuzzer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M791.11,-145.83C786.86,-137.55 781.73,-127.57 777.06,-118.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"780.09,-116.71 772.4,-109.42 773.86,-119.91 780.09,-116.71\"/>\n",
       "</g>\n",
       "<!-- InformationFlow&#45;&gt;GrammarMiner -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>InformationFlow-&gt;GrammarMiner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M836.03,-145.83C854.48,-136.41 877.21,-124.81 896.82,-114.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"898.57,-117.83 905.88,-110.16 895.38,-111.59 898.57,-117.83\"/>\n",
       "</g>\n",
       "<!-- APIFuzzer&#45;&gt;Carver -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>APIFuzzer-&gt;Carver</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M477.67,-78.44C486.88,-76.27 496.46,-74.05 505.45,-72 561.66,-59.21 625.33,-45.35 673.39,-35.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"674.36,-38.38 683.4,-32.86 672.89,-31.54 674.36,-38.38\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore\n",
    "if rich_output():\n",
    "    from IPython.display import SVG\n",
    "    sitemap = SVG(filename='PICS/Sitemap.svg')\n",
    "else:\n",
    "    sitemap = None\n",
    "sitemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But since even this map can be overwhelming, here are a few _tours_ to get you started.  Each of these tours allows you to focus on a particular view, depending on whether you are a programmer, student, or researcher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Pragmatic Programmer Tour\n",
    "\n",
    "You have a program to test.  You want to generate tests as quickly as possible and as thorough as possible. You don't care so much how something is implemented, but it should get the job done.  You want to get to the point.\n",
    "\n",
    "1. __Start with [Introduction to Testing](Intro_Testing.ipynb) to get the basic concepts.__  (You would know most of these anyway, but it can't hurt to get quick reminders).\n",
    "\n",
    "2. __Use the simple fuzzers from [the chapter on Fuzzers](Fuzzer.ipynb)__ to test your program against the first random inputs.\n",
    "\n",
    "3. __Get [coverage](Coverage.ipynb) from your program__ and use coverage information to [guide test generation towards code coverage](GreyboxFuzzer.ipynb).\n",
    "\n",
    "4. __Define an [input grammar](Grammars.ipynb) for your program__ and use this grammar to thoroughly fuzz your program with syntactically correct inputs.  As fuzzer, we would recommend a [grammar coverage fuzzer](GrammarCoverageFuzzer), as this ensures coverage of input elements.\n",
    "\n",
    "5. If you want __more control over the generated inputs,__ consider [probabilistic fuzzing](ProbabilisticGrammarFuzzer.ipynb) and [fuzzing with generator functions](GeneratorGrammarFuzzer.ipynb).\n",
    "\n",
    "6. If you want to __deploy a large set of fuzzers__, learn how to [manage a large set of fuzzers](FuzzingInTheLarge.ipynb).\n",
    "\n",
    "In each of these chapters, start with the \"Synopsis\" parts; these will give you quick introductions on how to use things, as well as point you to relevant usage examples.  With this, enough said.  Get back to work and enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Page-by-Page Tours\n",
    "\n",
    "These tours are how the book is organized.  Having gone through the [Introduction to Testing](Intro_Testing.ipynb) for the basic concepts, you can read your way through these parts:\n",
    "\n",
    "1. __The [lexical tour](02_Lexical_Fuzzing.ipynb)__  focuses on _lexical_ test generation techniques, i.e. techniques that compose an input character by character and byte by byte.  Very fast and robust techniques with a minimum of bias.\n",
    "\n",
    "1. __The [syntactical tour](03_Syntactical_Fuzzing.ipynb)__ focuses on _grammars_ as a means to specify the syntax of inputs.  The resulting test generators produce syntactically correct inputs, making tests much faster, and provide lots of control mechanisms for the tester.\n",
    "\n",
    "1. __The [semantical tour](04_Semantical_Fuzzing.ipynb)__ makes use of _code semantics_ to shape and guide test generation.  Advanced techniques include extracting input grammars, mining function specifications, and symbolic constraint solving to cover as many code paths as possible.\n",
    "\n",
    "1. __The [application tour](05_Domain-Specific_Fuzzing.ipynb)__ applies the techniques defined in the earlier parts on domains such as Web servers, user interfaces, APIs, or configurations.\n",
    "\n",
    "1. __The [management tour](06_Managing_Fuzzing.ipynb)__ finally focuses on how to handle and organize large sets of test generators, and when to stop fuzzing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Most of these chapters start with a \"Synopsis\" section that explains how to use the most important concepts.  You can choose whether you want a \"usage\" perspective (then just read the synopsis) or a \"understanding\" perspective (then read on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Undergraduate Tour\n",
    "\n",
    "You are a student of computer science and/or software engineering.  You want to know basics of testing and related fields.  You not only want to use techniques, but also dig deeper into algorithms and implementations.  We have the following recommendation for you:\n",
    "\n",
    "1. Start with [Introduction to Testing](Intro_Testing.ipynb) and [Coverage](Coverage.ipynb) to get the __basic concepts.__  (You may know some of these already, but hey, you're a student, right?)\n",
    "\n",
    "2. __Learn how simple fuzzers work__ from [the chapter on Fuzzers](Fuzzer.ipynb).  This already gives you tools that took down 30% of UNIX utilities in the 90s.  What happens if you test some tool that never has been fuzzed before?\n",
    "\n",
    "3. __[Mutation-based fuzzing](MutationFuzzer.ipynb)__ is pretty much the standard in fuzzing today: Take a set of seeds, and mutate them until we find a bug.\n",
    "\n",
    "4. __Learn how [grammars](Grammars.ipynb) can be used to generate syntactically correct inputs.__  This makes test generation much more efficient, but you have to write (or [mine](GrammarMiner.ipynb) a grammar in the first place.\n",
    "\n",
    "5. __Learn how to [fuzz APIs](APIFuzzer.ipynb) and [graphical user interfaces](GUIFuzzer.ipynb)__.  Both of these are important domains for software test generation.\n",
    "\n",
    "6. __Learn how to [reduce failure-inducing inputs](Reducer.ipynb) to a minimum automatically__.  This is a great time saver for debugging, especially in conjunction with automated testing.\n",
    "\n",
    "For all these chapters, experiment with the implementations to understand their concepts.  Feel free to experiment as you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If you are a teacher, the above chapters can be useful in programming and/or software engineering courses.  Make use of slides and/or live programming, and have students work on exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Graduate Tour\n",
    "\n",
    "On top of the \"Undergraduate\" tour, you want to get deeper into test generation techniques, including techniques that are more demanding.\n",
    "\n",
    "1. __[Search-based testing](SearchBasedFuzzer.ipynb)__ allows you to guide test generation towards specific goals, such as code coverage.  Robust and efficient.\n",
    "\n",
    "1. Get an introduction to __[configuration testing](ConfigurationFuzzer.ipynb)__.  How does one test and cover a system that comes with multiple configuration options?\n",
    "\n",
    "1. __[Mutation analysis](MutationAnalysis.ipynb)__ seeds synthetic defects (mutations) into program code to check whether the tests find them.  If the tests do not find mutations, they likely won't find real bugs either.\n",
    "\n",
    "1. __Learn how to [parse](Parser.ipynb) inputs__ using grammars.  If you want to analyze, decompose, mutate existing inputs, you need a parser for that.\n",
    "\n",
    "1. __[Concolic](ConcolicFuzzer.ipynb) and [symbolic](SymbolicFuzzer.ipynb) fuzzing__ solve constraints along program paths to reach code that is hard to test.  Used wherever reliability is paramount; also a hot research topic.\n",
    "\n",
    "1. __Learn how to [estimate when to stop fuzzing](WhenToStopFuzzing.ipynb)__.  There has to be a stop at some point, right?\n",
    "\n",
    "For all these chapters, experiment with the code; feel free to create your own variations and extensions.  This is how we get to research!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If you are a teacher, the above chapters can be useful in advanced courses on software engineering and testing.  Again, you can make use of slides and/or live programming, and have students work on exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Blackbox Tour\n",
    "\n",
    "This tour focuses on _black-box fuzzing_ – that is, techniques that work without feedback from the program under test. Have a look at\n",
    "\n",
    "1. __[Basic fuzzing](Fuzzer.ipynb)__.  This already gives you tools that took down 30% of UNIX utilities in the 90s.  What happens if you test some tool that never has been fuzzed before?\n",
    "\n",
    "2. __[Syntactical fuzzing](03_Syntactical_Fuzzing.ipynb)__ focuses on _grammars_ as a means to specify the syntax of inputs.  The resulting test generators produce syntactically correct inputs, making tests much faster, and provide lots of control mechanisms for the tester.\n",
    "\n",
    "3. __[Semantical fuzzing](FuzzingWithconstraints.ipynb)__ attaches _constraints_ to grammars, making inputs not only syntactically valid, but also _semantically_ valid - and empowering you to shape test inputs just like you want them,\n",
    "\n",
    "4. __[Domain-specific fuzzing](05_Domain-Specific_Fuzzing.ipynb)__ showing a number of applications of these techniques, from configurations to graphical user interfaces.\n",
    "\n",
    "5. If you want to __deploy a large set of fuzzers__, learn how to [manage a large set of fuzzers](FuzzingInTheLarge.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Whitebox Tour\n",
    "\n",
    "This tour focuses on _white-box fuzzing_ – that is, techniques that leverage feedback from the program under test. Have a look at\n",
    "\n",
    "1. __[Coverage](Coverage.ipynb)__ to get the basic concepts of coverage and how to measure it for Python.\n",
    "\n",
    "2. __[Mutation-based fuzzing](MutationFuzzer.ipynb)__ is pretty much the standard in fuzzing today: Take a set of seeds, and mutate them until we find a bug.\n",
    "\n",
    "3. __[Greybox fuzzing](GreyboxFuzzer.ipynb)__ with algorithms from the popular American Fuzzy Lop (AFL) fuzzer.\n",
    "\n",
    "4. __[Information Flow](InformationFlow.ipynb)__ and __[Concolic Fuzzing](ConcolicFuzzer.ipynb)__ showing how to capture information flow in Python programs and how to leverage it to produce more intelligent test cases.\n",
    "\n",
    "5. __[Symbolic Fuzzing](SymbolicFuzzer.ipynb)__, reasoning about the behavior of a program without executing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Researcher Tour\n",
    "\n",
    "On top of the \"Graduate\" tour, you are looking for techniques that are somewhere between lab stage and widespread usage – in particular, techniques where there is still room for lots of improvement.  If you look for research ideas, go for these topics.\n",
    "\n",
    "1. __[Mining function specifications](DynamicInvariants.ipynb)__ is a hot topic in research: Given a function, how can we infer an abstract model that describes its behavior?  The conjunction with test generation offers several opportunities here, in particular for dynamic specification mining.\n",
    "\n",
    "2. __[Mining input grammars](GrammarMiner.ipynb)__ promises to join the robustness and ease of use of lexical fuzzing with the efficiency and speed of syntactical fuzzing.  The idea is to mine an input grammar from a program automatically, which then serves as base for syntactical fuzzing.  Still in an early stage, but lots of potential.\n",
    "\n",
    "3. __[Probabilistic grammar fuzzing](ProbabilisticGrammarFuzzer.ipynb)__ gives programmers lots of control over which elements should be generated.  Plenty of research possibilities at the intersection of probabilistic fuzzing and mining data from given tests, as sketched in this chapter.\n",
    "\n",
    "4. __[Fuzzing with generators](GeneratorGrammarFuzzer.ipynb)__ and __[Fuzzing with constraints](FuzzingWithConstraints.ipynb)__ gives programmers the ultimate control over input generation, namely by allowing them to define their own generator functions or to define their own input constraints.  The big challenge is: How can one best exploit the power of syntactic descriptions with a minimum of contextual constraints?\n",
    "\n",
    "5. __[Carving unit tests](Carver.ipynb)__ brings the promise of speeding up test execution (and generation) dramatically, by extracting unit tests from program executions that replay only individual function calls (possibly with new, generated arguments).  In Python, carving is simple to realize; here's plenty of potential to toy with.\n",
    "\n",
    "6. __Testing [web servers](WebFuzzer.ipynb) and [GUIs](GUIFuzzer.ipynb)__ is a hot research field, fueled by the need of practitioners to test and secure their interfaces (and the need of other practitioners to break through these interfaces).  Again, there's still lots of unexplored potential here.\n",
    "\n",
    "7. __[Greybox fuzzing](GreyboxFuzzer.ipynb) and [greybox fuzzing with grammars](GreyboxGrammarFuzzer.ipynb)__  bring in _statistical estimators_ to guide test generation towards inputs and input properties that are most likely to discover new bugs.  The intersection of testing, program analysis, and statistics offers lots of possibilities for future research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For all these topics, having Python source available that implements and demonstrates the concepts is a major asset.  You can easily extend the implementations with your own ideas and run evaluations right in a notebook.  Once your approach is stable, consider porting it to a language with a wider range of available subjects (such as C, for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Author Tour\n",
    "\n",
    "This is the ultimate tour – you have learned everything there is and want to contribute to the book.  Then, you should read two more chapters:\n",
    "\n",
    "1. The __[guide for authors](Guide_for_Authors.ipynb)__ gives an introduction on how to contribute to this book (coding styles, writing styles, conventions, and more).\n",
    "\n",
    "2. The __[template chapter](Template.ipynb)__ serves as a blueprint for your chapter.\n",
    "\n",
    "If you want to contribute, feel free to contact us – preferably before writing, but after writing is fine just as well.  We will be happy to incorporate your material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* You can go through the book from beginning to end...\n",
    "* ...but it may be preferable to follow a specific tour, based on your needs and resources.\n",
    "* Now [go and explore generating software tests](index.ipynb)!"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
